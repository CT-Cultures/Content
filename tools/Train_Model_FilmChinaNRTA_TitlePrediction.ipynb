{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train_Model_FilmChinaNRTA_TitlePrediction.ipynb","provenance":[],"collapsed_sections":["TPqso2f_-hG4"],"toc_visible":true,"authorship_tag":"ABX9TyOpoc4ZAcDqnH1oBV7wOF04"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b0b06c64704743198421e9fc00370c27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_050ed22cf398452b83b9a95f7218f3ed","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_17484bae0dcc455db55e565454d199fc","IPY_MODEL_c05779239f98412ebe432105b01e8fce"]}},"050ed22cf398452b83b9a95f7218f3ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17484bae0dcc455db55e565454d199fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0460d7abbb74466aa928d7c1f3387da9","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":9621,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9621,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5b73531a21d4219993ddd40c7885e78"}},"c05779239f98412ebe432105b01e8fce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1c6834b50cc04f2d866da15a6815413c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9621/9621 [13:54&lt;00:00, 11.52ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_85038ad7d2a240e0a5f7aa3b7bb5cf4f"}},"0460d7abbb74466aa928d7c1f3387da9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f5b73531a21d4219993ddd40c7885e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c6834b50cc04f2d866da15a6815413c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"85038ad7d2a240e0a5f7aa3b7bb5cf4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4bccabd4209749d0a80730805fbe7506":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_134bb1b0d68041f3a8eb28bf68a4a91a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a211482794a64163a7c8afd083265c28","IPY_MODEL_1b4eb46b55314921b15bac46bdeeea1a"]}},"134bb1b0d68041f3a8eb28bf68a4a91a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a211482794a64163a7c8afd083265c28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0aae521b1c88436c85191a4159ebaa77","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":535,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":535,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d03e7b8965d4409bddf1b38f985d509"}},"1b4eb46b55314921b15bac46bdeeea1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_41fa2f955e2e49b4940292231dc50bf1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 535/535 [00:03&lt;00:00, 174.11ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_023ecb53d4a445209472be6e60534877"}},"0aae521b1c88436c85191a4159ebaa77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6d03e7b8965d4409bddf1b38f985d509":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41fa2f955e2e49b4940292231dc50bf1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"023ecb53d4a445209472be6e60534877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"344b2e012cfd460996b1fb5f0d136311":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1103ab42d31e4a5d801f1d55ef5d35b6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_561bbd3124034c7fad3fdeb7ecd520a2","IPY_MODEL_362ae8e931d44b29b915f7b24ae5a0c4"]}},"1103ab42d31e4a5d801f1d55ef5d35b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"561bbd3124034c7fad3fdeb7ecd520a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_00ee5f61d7b442b4b812eaa331d1e720","_dom_classes":[],"description":"Downloading: ","_model_name":"FloatProgressModel","bar_style":"success","max":2170,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2170,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8ab86a3c1e814171a6d2270b2d42c10a"}},"362ae8e931d44b29b915f7b24ae5a0c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_13ce3d59e3da4b809db7eb0247e7378c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.61k/? [00:00&lt;00:00, 37.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a08583920cb44cd8826f8011f7f6e8d5"}},"00ee5f61d7b442b4b812eaa331d1e720":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8ab86a3c1e814171a6d2270b2d42c10a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13ce3d59e3da4b809db7eb0247e7378c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a08583920cb44cd8826f8011f7f6e8d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-6l1yfy8DoBT"},"source":["Training a Summarization Model to Predict Title"]},{"cell_type":"markdown","metadata":{"id":"JlM5Ry18-dLY"},"source":["# [1] Mount Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9bw0EfjVZQJn","executionInfo":{"status":"ok","timestamp":1626726452414,"user_tz":420,"elapsed":16713,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"8557da02-94d3-417f-de79-aa5095fe47a1"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TPqso2f_-hG4"},"source":["# [2] Install requirements, Load Lib, Set WD"]},{"cell_type":"code","metadata":{"id":"P4XT4IECgb6p","executionInfo":{"status":"ok","timestamp":1626726465428,"user_tz":420,"elapsed":13021,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}}},"source":["%%capture\n","!pip install transformers\n","!pip install datasets\n","!pip install rouge_score"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1W8pKHWECxq"},"source":["import pandas as pd\n","import numpy as np\n","import os\n","import gc\n","import torch\n","\n","import torch\n","from transformers import DataCollatorWithPadding\n","from datasets import Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jfy8ooT7EGD5"},"source":["path_wd = '/content/drive/MyDrive/Github/Content'\n","path_NRTA = '/content/drive/MyDrive/Github/Content/sources/NRTA'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lt-AtAk_f4A2"},"source":["# [3] Prepare Data for Classification with Pandas"]},{"cell_type":"markdown","metadata":{"id":"tWEdJ61xZILq"},"source":["## Intantiate tokenizer for summarization"]},{"cell_type":"code","metadata":{"id":"LEjnJDdCY_i6"},"source":["from transformers import AutoTokenizer\n","# Instantiate tokenizer\n","checkpoint = \"uer/bart-base-chinese-cluecorpussmall\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u14lHTP9wWNN"},"source":["##  Import Records, Combine and Clean"]},{"cell_type":"code","metadata":{"id":"sHk_LsvMf3v1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626721599338,"user_tz":420,"elapsed":32237,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"7a10de17-5b6b-4093-d56d-6bb70027027a"},"source":["# NRTA\n","path_NRTA = '/content/drive/MyDrive/Github/Content/sources/NRTA'\n","dftv = pd.read_json(path_NRTA + '/records/contents_of_registrations.json')\n","dftv = dftv[['剧名', '内容提要']]\n","dftv.columns=['title', 'summary']\n","\n","# ChinaFilm\n","path_ChinaFilm = '/content/drive/MyDrive/Github/Content/sources/ChinaFilm'\n","dfmovie = pd.read_csv(path_ChinaFilm + '/records/contents_of_registrations.csv', \n","                      index_col=0, encoding='utf-8-sig')\n","dfmovie = dfmovie[['片名', '梗概']]\n","dfmovie.columns=['title', 'summary']\n","\n","# Combine dftv and dfmovie\n","df = pd.concat([dftv, dfmovie], ignore_index=True)\n","df['title'] = df['title'].str.lstrip('《').str.rstrip('》')\n","df = df.dropna()\n","\n","# Calculate token numbers for title and summary\n","# describe title token  count: range=[1,29], mean=4.9\n","df['title_tc'] = df['title'].apply(lambda x: len(tokenizer.tokenize(x)))\n","# describe summary token count: range=[1,446], mean=140, \n","df['summary_tc'] = df['summary'].apply(lambda x: len(tokenizer.tokenize(x)))\n","\n","\n","df.info()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (299 > 128). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 42759 entries, 0 to 42758\n","Data columns (total 4 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   title       42759 non-null  object\n"," 1   summary     42759 non-null  object\n"," 2   title_tc    42759 non-null  int64 \n"," 3   summary_tc  42759 non-null  int64 \n","dtypes: int64(2), object(2)\n","memory usage: 1.6+ MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8GMk9CidZSpj"},"source":["## Separate df into train, val and test, stratified"]},{"cell_type":"code","metadata":{"id":"XnAV6J_IOSTx"},"source":["# Separate title into groups by tc\n","intervals_title_tc = pd.cut(df['title_tc'], [0 ,2, 4, 8, 32])\n","df['title_group'] = df.groupby(intervals_title_tc).keys\n","\n","# Separate sumamry into groups by tc\n","intervals_summary_tc = pd.cut(df['summary_tc'], [0, 128, 256, 512])\n","df['summary_group'] = df.groupby(intervals_summary_tc).keys"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2YZtmV4Q2am"},"source":["# Split dataset into train, val and test with balanced groups\n","df_train = df.groupby(['summary_group', 'title_group']).sample(\n","    frac=0.9, random_state=42)[['title', 'summary']].copy()\n","df_not_train = df[~df.index.isin(df_train.index)]\n","df_val = df_not_train.groupby(['summary_group', 'title_group']).sample(\n","  frac=0.5, random_state=42)[['title', 'summary']].copy()\n","df_test = df_not_train[~df_not_train.index.isin(df_val.index)][\n","  ['title', 'summary']].copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"id":"2fdsxDBpUwLW","executionInfo":{"status":"ok","timestamp":1626723616698,"user_tz":420,"elapsed":23,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"f71e56bf-8e60-4d52-c634-1dc3a500c842"},"source":["# Sanity Check\n","df_test.head(2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>19</th>\n","      <td>大三女生</td>\n","      <td>故事发生在一所北方大学校园。人工智能专业大三女生赵嘉欣和白凌同时入选“类人足球机器人”研发团...</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>谁家的孩子</td>\n","      <td>夏子鹏的“虎妈”要求严格，他努力地使自己更优秀，但又经常碰上困扰</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    title                                            summary\n","19   大三女生  故事发生在一所北方大学校园。人工智能专业大三女生赵嘉欣和白凌同时入选“类人足球机器人”研发团...\n","72  谁家的孩子                   夏子鹏的“虎妈”要求严格，他努力地使自己更优秀，但又经常碰上困扰"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"PBkTr8cHRHkQ"},"source":["## Clean Memory"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180},"id":"pg9UKRYxRKDl","executionInfo":{"status":"error","timestamp":1626723621680,"user_tz":420,"elapsed":141,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"692fc1e3-77c0-49cf-e949-5f1c0cff9306"},"source":["del dftv, dfmovie, df\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-f9993825bc0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdftv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfmovie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dftv' is not defined"]}]},{"cell_type":"code","metadata":{"id":"OBoDvMJREJQm"},"source":["# Free up some memory\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1BJ9llva9mDA"},"source":["# [4] Setup For Finetuning - Summarization"]},{"cell_type":"markdown","metadata":{"id":"nU6FAEPJE2Y7"},"source":["## Define Key Training Parameters"]},{"cell_type":"code","metadata":{"id":"Lgwn29gvExmL"},"source":["#########################\n","PATH_SAVE = '/content/drive/MyDrive/Github/Content/tools/models/'\n","BATCH_SIZE = 4\n","DFTRAIN = df_train # df_genre_train\n","DFVAL = df_val # df_genre_val\n","DFTEST = df_test\n","MAX_INPUT_LENGTH = 448\n","MAX_OUTPUT_LENGTH = 36\n","MIN_OUTPUT_LENGTH = 1\n","#########################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gGYAzxZw-boz"},"source":["## Instaniate tokenizer and model\n","\n","\"uer/bart-base-chinese-cluecorpussmall\""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqHH3y5MKP0I","executionInfo":{"status":"ok","timestamp":1626694397074,"user_tz":420,"elapsed":9119,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"f47e08f1-b643-4968-e5b5-72c29dcd6c44"},"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer,BartForConditionalGeneration\n","\n","# assign device\n","if torch.cuda.device_count() > 0:\n","  device = 'cuda:' + str(torch.cuda.current_device())\n","else:\n","  device = 'cpu'\n","\n","# Instantiate tokenizer and model\n","checkpoint = \"uer/bart-base-chinese-cluecorpussmall\"\n","tokenizer = AutoTokenizer.from_pretrained(\n","    checkpoint, \n","    problem_type=\"summarization\")\n","model = BartForConditionalGeneration.from_pretrained(\n","    checkpoint, \n","    problem_type=\"summarization\",\n",")\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loading configuration file https://huggingface.co/uer/bart-base-chinese-cluecorpussmall/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/302d5765382fb3187d28afa2e6ea793a91f10ce34163e57678373af3f5194d7c.aae8bfff1f5703ae7f17be35d056b7bb21839c9bed053a2f0759f9c0a43ce4d0\n","Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.1,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 101,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.1,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 0,\n","  \"forced_eos_token_id\": 0,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"problem_type\": \"summarization\",\n","  \"scale_embedding\": false,\n","  \"tie_word_embeddings\": 0,\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"transformers_version\": \"4.8.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 21128\n","}\n","\n","loading file https://huggingface.co/uer/bart-base-chinese-cluecorpussmall/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/68a98551f47464131ddeff325158aaa18253dfe99fe69ff5eda453ae76e3c176.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n","loading file https://huggingface.co/uer/bart-base-chinese-cluecorpussmall/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/uer/bart-base-chinese-cluecorpussmall/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/uer/bart-base-chinese-cluecorpussmall/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/1255f13ee487ed54af54ff4250645a5682556603f07af2a0c7f0da1af7c7c238.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","loading file https://huggingface.co/uer/bart-base-chinese-cluecorpussmall/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/019394350641d3bec31d4b5db84db0f172f3493e813e82fe0444c54821fe0f91.ee60dc4fce36b9f8af761aa570e77d91cd1ef3698907d5a98dcc367c2464a73f\n","loading configuration file https://huggingface.co/uer/bart-base-chinese-cluecorpussmall/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/302d5765382fb3187d28afa2e6ea793a91f10ce34163e57678373af3f5194d7c.aae8bfff1f5703ae7f17be35d056b7bb21839c9bed053a2f0759f9c0a43ce4d0\n","Model config BartConfig {\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"gelu\",\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.1,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 101,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.1,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 0,\n","  \"forced_eos_token_id\": 0,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"bart\",\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"problem_type\": \"summarization\",\n","  \"scale_embedding\": false,\n","  \"tie_word_embeddings\": 0,\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"transformers_version\": \"4.8.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 21128\n","}\n","\n","loading weights file https://huggingface.co/uer/bart-base-chinese-cluecorpussmall/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/2a69039766de1719a6bcffd9d790af647756b2c6499a2794b0e72855170a545d.2cc1c08ff2474dd4a074fcf0c889df546f3ac56a3762cf3afbc68d14083f8584\n","All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","All the weights of BartForConditionalGeneration were initialized from the model checkpoint at uer/bart-base-chinese-cluecorpussmall.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(21128, 768, padding_idx=0)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(21128, 768, padding_idx=0)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(21128, 768, padding_idx=0)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"pbJcL07h91x4"},"source":["## Feed pandas df through DataSet"]},{"cell_type":"code","metadata":{"id":"RdoT1iUC8lkx"},"source":["# instaniate data_collator\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","# define function to process pd.DataFrame to datasets.Datasets\n","def process_data_to_model_inputs(batch):\n","    # tokenize the inputs and labels\n","    inputs = tokenizer(\n","        batch[\"summary\"],\n","        #padding='max_length', use data_collater for dynamic padding\n","        truncation=True,\n","        max_length=MAX_INPUT_LENGTH,\n","    )\n","\n","    outputs = tokenizer(\n","        batch[\"title\"],\n","        padding='max_length',\n","        truncation=True,\n","        max_length=MAX_OUTPUT_LENGTH,\n","    )\n","\n","    batch[\"input_ids\"] = inputs.input_ids\n","    batch[\"attention_mask\"] = inputs.attention_mask\n","    batch[\"labels\"] = outputs.input_ids\n","\n","    # We have to make sure that the PAD token is ignored\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n","        for labels in batch[\"labels\"]\n","    ]\n","\n","    return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["b0b06c64704743198421e9fc00370c27","050ed22cf398452b83b9a95f7218f3ed","17484bae0dcc455db55e565454d199fc","c05779239f98412ebe432105b01e8fce","0460d7abbb74466aa928d7c1f3387da9","f5b73531a21d4219993ddd40c7885e78","1c6834b50cc04f2d866da15a6815413c","85038ad7d2a240e0a5f7aa3b7bb5cf4f","4bccabd4209749d0a80730805fbe7506","134bb1b0d68041f3a8eb28bf68a4a91a","a211482794a64163a7c8afd083265c28","1b4eb46b55314921b15bac46bdeeea1a","0aae521b1c88436c85191a4159ebaa77","6d03e7b8965d4409bddf1b38f985d509","41fa2f955e2e49b4940292231dc50bf1","023ecb53d4a445209472be6e60534877"]},"id":"Jiq47dJxpQhb","executionInfo":{"status":"ok","timestamp":1626692019241,"user_tz":420,"elapsed":23213,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"ad1caf36-3b61-403b-955a-58b53bd775ce"},"source":["# Load Train, Val into DataSet\n","\n","dataset_train = Dataset.from_pandas(DFTRAIN)\n","dataset_train = dataset_train.map(\n","  process_data_to_model_inputs,\n","  batched=True,\n","  batch_size=BATCH_SIZE,\n","  remove_columns=['__index_level_0__', 'title', 'summary'],\n",")\n","dataset_train.set_format(\n","  type=\"torch\",\n","  columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",")\n","dataset_val = Dataset.from_pandas(DFVAL)\n","dataset_val = dataset_val.map(\n","  process_data_to_model_inputs,\n","  batched=True,\n","  batch_size=BATCH_SIZE,\n","  remove_columns=['__index_level_0__', 'title', 'summary'],\n",")\n","dataset_val.set_format(\n","  type=\"torch\",\n","  columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0b06c64704743198421e9fc00370c27","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9621.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bccabd4209749d0a80730805fbe7506","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=535.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LR8vac6fhFYh","executionInfo":{"status":"ok","timestamp":1626692028189,"user_tz":420,"elapsed":468,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"ee535759-5846-45d6-d3e8-6eef9537f256"},"source":["# Sanity Check\n","dataset_train[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]),\n"," 'input_ids': tensor([ 101, 3926, 1045, 5328,  753, 1282, 2399, 1724, 3299, 8024,  711, 6375,\n","         2495, 1744, 6863, 5670,  683, 2157, 2128, 1059, 2850, 6809, 4886, 2336,\n","         5670, 3124, 2229, 8024, 7259, 2360, 7357, 3633, 7599, 2372, 7566, 3696,\n","         7313,  721, 1894, 6566, 6569, 2844, 6843, 2339,  868, 8024,  830,  782,\n","         1728, 2824, 6437, 6825, 5310, 1762,  671, 6629, 8024,  676, 1921,  676,\n","         1915, 2894, 3818,  671, 5579, 4178, 6117, 8024,  809, 2673, 4164, 4295,\n","         4291,  711,  807,  817, 8024, 5106, 4810,  749, 3189, 3315, 3324, 2797,\n","         4638, 3266, 3324, 6369, 1153, 8024, 3297, 5303, 2199,  683, 2157, 2128,\n","         1059, 6843, 6809, 4886, 2336,  102]),\n"," 'labels': tensor([ 101,  721, 7259,  102, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])}"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"KeYp9abw1lC7"},"source":["## define compute_metric function"]},{"cell_type":"code","metadata":{"id":"5hRGTzX42KkD","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["344b2e012cfd460996b1fb5f0d136311","1103ab42d31e4a5d801f1d55ef5d35b6","561bbd3124034c7fad3fdeb7ecd520a2","362ae8e931d44b29b915f7b24ae5a0c4","00ee5f61d7b442b4b812eaa331d1e720","8ab86a3c1e814171a6d2270b2d42c10a","13ce3d59e3da4b809db7eb0247e7378c","a08583920cb44cd8826f8011f7f6e8d5"]},"executionInfo":{"status":"ok","timestamp":1626726314692,"user_tz":420,"elapsed":1205,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"370c94ad-3b67-4c98-c1e1-361c7411c144"},"source":["from datasets import load_metric\n","rouge = load_metric(\"rouge\")\n","\n","def compute_metrics(pred):\n","    labels_ids = pred.label_ids\n","    pred_ids = pred.predictions\n","\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n","\n","    rouge_output = rouge.compute(\n","        predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"]\n","    )[\"rouge1\"].mid\n","\n","    return {\n","        \"rouge1_precision\": round(rouge_output.precision, 4),\n","        \"rouge1_recall\": round(rouge_output.recall, 4),\n","        \"rouge1_fmeasure\": round(rouge_output.fmeasure, 4),\n","    }"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"344b2e012cfd460996b1fb5f0d136311","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2170.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wPv6alHW_OGW"},"source":["## Instaniate training_args and Trainer"]},{"cell_type":"code","metadata":{"id":"VFHbgeAL0J_w","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"error","timestamp":1626726316484,"user_tz":420,"elapsed":188,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"b8e0bfa8-10b0-4245-e1db-97da79ecc467"},"source":["from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir= PATH_SAVE,\n","    predict_with_generate=True,\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    fp16=True,\n","    logging_steps=100,\n","    eval_steps=100,\n","    save_steps=100,\n","    gradient_accumulation_steps=4,\n","    load_best_model_at_end=True,\n","    save_total_limit=2,\n","    num_train_epochs=1,\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model,\n","    training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-5b4bcfe3feb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mload_best_model_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msave_total_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/training_args_seq2seq.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, save_strategy, save_steps, save_total_limit, save_on_each_node, no_cuda, seed, fp16, fp16_opt_level, fp16_backend, fp16_full_eval, local_rank, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, deepspeed, label_smoothing_factor, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, sortish_sampler, predict_with_generate)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_full_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             raise ValueError(\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0;34m\"Mixed precision training with AMP or APEX (`--fp16`) and FP16 evaluation can only be used on CUDA devices.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_to\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Mixed precision training with AMP or APEX (`--fp16`) and FP16 evaluation can only be used on CUDA devices."]}]},{"cell_type":"markdown","metadata":{"id":"Fx6t86oN_YcS"},"source":["# [5] Train and SAVE"]},{"cell_type":"code","metadata":{"id":"WlN3MScBeu61"},"source":["trainer.train()\n","#resume_from_checkpoint=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dc5hGx4cpsGc","executionInfo":{"status":"ok","timestamp":1626719506231,"user_tz":420,"elapsed":3493,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"74afddce-afb1-4b94-a7f2-ccaad7f4e2f5"},"source":["# Save Model\n","\n","trainer.save_model(PATH_SAVE + '/' + 'bart-base-chinese-cluecorpussmall-FilmChina-and-NRTA-titleprediction')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model checkpoint to /content/drive/MyDrive/Github/Content/tools/models//bart-base-chinese-cluecorpussmall-FilmChina-and-NRTA-titleprediction\n","Configuration saved in /content/drive/MyDrive/Github/Content/tools/models//bart-base-chinese-cluecorpussmall-FilmChina-and-NRTA-titleprediction/config.json\n","Model weights saved in /content/drive/MyDrive/Github/Content/tools/models//bart-base-chinese-cluecorpussmall-FilmChina-and-NRTA-titleprediction/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/Github/Content/tools/models//bart-base-chinese-cluecorpussmall-FilmChina-and-NRTA-titleprediction/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Github/Content/tools/models//bart-base-chinese-cluecorpussmall-FilmChina-and-NRTA-titleprediction/special_tokens_map.json\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"uT0rC4crImBd"},"source":["#[6] TEST"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"rAX7U6ONKYWI","executionInfo":{"status":"error","timestamp":1626721781330,"user_tz":420,"elapsed":266,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"7f8e26f3-a6c4-48dd-f595-ed0d0350a163"},"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer,BartForConditionalGeneration\n","\n","# assign device\n","if torch.cuda.device_count() > 0:\n","  device = 'cuda:' + str(torch.cuda.current_device())\n","else:\n","  device = 'cpu'\n","\n","# Instantiate tokenizer and model\n","model_name = \"/content/drive/MyDrive/Github/Content/tools/models/bart-base-chinese-cluecorpussmall-FilmChina-and-NRTA-titleprediction\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","model.to(device)\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-51dafea924cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Github/Content/tools/models/bart-base-chinese-cluecorpussmall-FilmChina-and-NRTA-titleprediction\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0;32m--> 390\u001b[0;31m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             )\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;31m# Fallback: use pattern matching on the string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, config_dict, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mreturn_unused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"return_unused_kwargs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pruned_heads\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bart/configuration_bart.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, max_position_embeddings, encoder_layers, encoder_ffn_dim, encoder_attention_heads, decoder_layers, decoder_ffn_dim, decoder_attention_heads, encoder_layerdrop, decoder_layerdrop, activation_function, d_model, dropout, attention_dropout, activation_dropout, init_std, classifier_dropout, scale_embedding, gradient_checkpointing, use_cache, num_labels, pad_token_id, bos_token_id, eos_token_id, is_encoder_decoder, decoder_start_token_id, forced_eos_token_id, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mforced_eos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced_eos_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         )\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_problem_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             raise ValueError(\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0;34mf\"The config parameter `problem_type` wasnot understood: received {self.problem_type}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;34m\"but only 'regression', 'single_label_classification' and 'multi_label_classification' are valid.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: The config parameter `problem_type` wasnot understood: received summarizationbut only 'regression', 'single_label_classification' and 'multi_label_classification' are valid."]}]},{"cell_type":"code","metadata":{"id":"DbkuVMAADy-v"},"source":["model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k3NpF0lT7WMc"},"source":["s = df_test.loc[19,'summary']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HnM7mO5z7hzj"},"source":["def str_predict_title(s: str) -> str:\n","  tokens = tokenizer.tokenize(s)\n","  input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","  predicted = model.generate(input_ids)\n","  tokenize.decode(predicted)\n","  return predicted_title\n","\n","str_predict_title(s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hq9DjRZhBsTl","executionInfo":{"status":"ok","timestamp":1626719480370,"user_tz":420,"elapsed":275,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"6ff1d325-f44e-4433-bb7b-c83081a1094d"},"source":["input = tokenizer(s)\n","model.name_or_path"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'uer/bart-base-chinese-cluecorpussmall'"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"XfKFAzVNIsjF","executionInfo":{"status":"error","timestamp":1626721755115,"user_tz":420,"elapsed":247,"user":{"displayName":"Xu Vee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNTzTx2PmIBbypp7-eWIRwMo4-I9DLyTz70KE9_g=s64","userId":"12955926615284697296"}},"outputId":"c8cda9f4-7531-4dfb-f468-70a8bb9d57f2"},"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer,BartForConditionalGeneration\n","import torch\n","############\n","model_name = PATH_SAVE + '/' + m_name + '-FilmChina-and-NRTA-titleprediction'\n","############\n","if torch.cuda.device_count() > 0:\n","  device = 'cuda:' + str(torch.cuda.current_device())\n","else:\n","  device = 'cpu'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = BartForConditionalGeneration.from_pretrained(\n","  model_name,\n","  problem_type=\"summarization\",\n",").to(device)\n","model.eval() # set model to eval mode for faster prediction"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-21f4a5dc2d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPATH_SAVE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-FilmChina-and-NRTA-titleprediction'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'm_name' is not defined"]}]},{"cell_type":"code","metadata":{"id":"nRDp9hpc_bpk"},"source":["batch_size = 8\n","i = 0\n","ls = df_test['summary'].tolist()\n","softmax = torch.nn.Softmax(dim=-1)\n","L = df_genre_test.shape[0]\n","test_predictions = []\n","\n","while i < L:\n","  batch_test = tokenizer(ls[i:i+batch_size],\n","                           padding=True,\n","                           max_length=512, \n","                           truncation=True, \n","                           return_tensors='pt')\n","  batch_test.to(device)\n","  batch_outputs = model(**batch_test)\n","  batch_logtis = batch_outputs.logits\n","  batch_softmax = softmax(batch_logtis)\n","  batch_results = torch.argmax(batch_softmax, dim=1).cpu().numpy()\n","  test_predictions.extend(list(batch_results))\n","  i += batch_size"],"execution_count":null,"outputs":[]}]}